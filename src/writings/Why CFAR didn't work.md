---
title: Why CFAR didn't get farther with a "real/efficacious art of rationality"
tags:
  - notes
---
Source: https://www.lesswrong.com/posts/B9kP6x5rpmuCzpfWb/comment-reply-my-low-quality-thoughts-on-why-cfar-didn-t-get

### Highlights
- My lead guess is that the barriers and tricky spots we ran into are somewhat similar to those that lots of efforts at self-help / human potential movement / etc. things have run into, and are basically **"it's easy and locally reinforcing to follow gradients toward what one might call 'guessing the student's password', and much harder and much less locally reinforcing to reason/test/whatever one's way toward a real art of rationality. Also, the process of following these gradients tends to corrupt one's ability to reason/care/build real stuff, as does assimilation into many parts of wider society."**
- But there's a thing near "self-help" that I'll be trying to dodge in later iterations of mainline-esque workshops, if there are later iterations.  I think.  If you like, you can think with some accuracy of the small workshop we're running this week, and its predecessor workshop a couple months ago, as experiments toward having a workshop where people stay outward-directed (stay focused on inquiring into outside things, or building stuff, or otherwise staring at the world outside their own heads) rather than focusing on e.g. acquiring "rationality habits" that involve a conforming of one's own habits/internal mental states with some premade plan.
- when people try to re-order their own or other peoples’ psyches based on theories of what’s useful, it’s easy to mess things up.
- So, IMO, the history of efforts at self-improvement or rationality or the human potential movement or similar is full of efforts to rewire the psyche into molds that seem like a good idea initially, and sometimes seem like a bad idea in hindsight.  And this sort of error is a bit tricky to recover from, because, if you’re changing how your mind works or how your social scene works, you are thereby messing with the faculties you’ll later need to use to evaluate the change, and to notice and recover from errors.
- Some examples of the “impure” motives I have in mind:

- In groups:

	- Participants may want to learn “rationality”/“CFAR techniques”/etc. so that they can feel cool, so others will think they’re cool, so they can be part of the group, so they can gain the favor of a “teacher” or other power structure, etc.
	- Instructor-y types may want people to think our techniques are cool so that we’ll be in positions of power/influence/control; (or so that we can think we’re cool, or so we can keep covering up some blind spot of our own by getting everyone else to have it too)
	- Organizations may want to select people who appear to have a certain sort of psyche so they can predict or control those people, and this can itself cause would-be recruits for that organization to want to appear to be that way, and so on.  (CS Lewis’s “[inner ring](https://www.lewissociety.org/innerring/)” concept covers some of this, but it can get extra wonky once you bring in explicit techniques for modeling and changing the psyche, IMO.)
- So, in summary: people's desires to control one another, or fool one another, can combine poorly with techniques for psychological self- or other- modification.  So, too, with people's desires to control their own psyches, or to fool themselves, or to dodge uncertainty.  Such failure modes are particularly easy because we do not have good models of how the psyche, or the sociology, ought to work, and it is relatively easy to manage to be "honestly mistaken" in convenient ways in view of that ignorance.
- In  [Something to Protect](https://www.lesswrong.com/posts/SGR4GxFK7KmW7ckCB/something-to-protect) , Eliezer argues that the real power in rationality will come when it is developed for the sake of some outside thing-worth-caring-about that a person cares deeply about, rather than developed for the sake of "being very rational" or some such.
- Relatedly, in [Mandatory Secret Identities](https://www.lesswrong.com/posts/gBewgmzcEiks2XdoQ/mandatory-secret-identities), Eliezer advocates requiring that teachers of rationality have a serious day job / hobby / non-rationality-teacher engagement with how to do something difficult, and that they do enough real accomplishment to warrant respect in this other domain, and that no one be respected more as a teacher of rationality than as an accomplisher of other real stuff.  That is, he suggested we try to get respect for real traction on real, non-"rationality" tasks into any rationality dojo's social incentives.
- Unfortunately, our CFAR curriculum development efforts mostly had no such strong outside mooring.  That is, CFAR units rose or fell based on e.g. how much we were personally convinced they were useful, and how much the students seemed to like them and seemed to be changed by them, how much we liked the resultant changes in our students, (both immediately and at follow-ups months or years later), etc. -- but not based (much/enough) on whether those units helped us/them/whoever make real, long-term progress on outside problems.